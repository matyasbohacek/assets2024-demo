# ASSETS 2024 Demo

<br>

> ### Pose-aware Large Language Model Interface for Providing Feedback to Sign Language Learners
> Sign language learners often find it challenging to self-identify and correct mistakes, and so many turn to automated methods providing sign language feedback. However, they find that existing methods either require specialized equipment or lack robustness. They, therefore, have to seek human tutors or resign on the inquiry altogether. To overcome the barriers in accessibility and robustness, we build a large language model (LLM)-based tool for providing feedback to sign language learners. The tool can analyze videos from diverse camera and background settings without specialized equipment thanks to a sign language segmentation and keyframe identification model. Using a pose-aware LLM, the tool can then produce feedback in natural language. We present our tool as a demo web application, opening its implementation into specialized learning applications.

<br>

## Tasks: 
